{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "* Download the \"Assignment.ipynb\" notebook \n",
    "* Fill in the code in the cells marked with #GRADED#\n",
    "* Code cells outside of #GRADED# will not be considered for grading. \n",
    "  * Feel free to write outside of it for debugging\n",
    "* Submit the updated notebook\n",
    "  * Make sure to save your changes before submitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n",
      "(a).shape\n",
      "(3, 5)\n",
      "number of dimensions\n",
      "2\n",
      "type of elements in the numpy array arr\n",
      "int32\n",
      "==================================================\n",
      "(b).The sum of elements\n",
      "105\n",
      "==================================================\n",
      "(c).The mean of elements\n",
      "7.0\n",
      "==================================================\n",
      "(d).an array of the same shape as arr but filled with zeros\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "==================================================\n",
      "(e).an array of the same shape as arr but filled with ones\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "==================================================\n",
      "(f).an array of the same shape as arr but where all elements are squared values\n",
      "[[  0   1   4   9  16]\n",
      " [ 25  36  49  64  81]\n",
      " [100 121 144 169 196]]\n",
      "==================================================\n",
      "(g).an array result of shape 3*3\n",
      "[[ 30  80 130]\n",
      " [ 80 255 430]\n",
      " [130 430 730]]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "arr = np.arange(15).reshape(3, 5)\n",
    "print(arr)\n",
    "# (a) Determine the shape, number of dimensions and type of elements in the numpy array arr\n",
    "print(\"(a).shape\")\n",
    "print(arr.shape)\n",
    "\n",
    "print(\"number of dimensions\")\n",
    "print(arr.ndim)\n",
    "\n",
    "print(\"type of elements in the numpy array arr\")\n",
    "print(arr.dtype)\n",
    "\n",
    "# (b) Determine the sum of elements in arr\n",
    "print(\"=====\"*10)\n",
    "print(\"(b).The sum of elements\")\n",
    "print(arr.sum())\n",
    "\n",
    "# (c) Determine the mean of elements in arr\n",
    "print(\"=====\"*10)\n",
    "print(\"(c).The mean of elements\")\n",
    "print(arr.mean())\n",
    "\n",
    "# (d) Create an array of the same shape as arr but filled with zeros\n",
    "print(\"=====\"*10)\n",
    "print(\"(d).an array of the same shape as arr but filled with zeros\")\n",
    "array_zeros = np.zeros(arr.shape)\n",
    "print(array_zeros)\n",
    "\n",
    "# (e) Create an array of the same shape as arr but filled with ones\n",
    "print(\"=====\"*10)\n",
    "print(\"(e).an array of the same shape as arr but filled with ones\")\n",
    "array_ones = np.ones(arr.shape)\n",
    "print(array_ones)\n",
    "\n",
    "# (f) Create an array of the same shape as arr but where all elements are squared values\n",
    "print(\"=====\"*10)\n",
    "print(\"(f).an array of the same shape as arr but where all elements are squared values\")\n",
    "array_sq = np.square(arr)\n",
    "print(array_sq)\n",
    "\n",
    "# (g) Create an array result of shape 3*3 resulting from multiplication of arr with transpose(arr). Hint: use np.dot\n",
    "print(\"=====\"*10)\n",
    "print(\"(g).an array result of shape 3*3\")\n",
    "arr_T = np.transpose(arr)\n",
    "array1 = np.dot(arr,arr_T)\n",
    "print(array1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "5           5.4          3.9           1.7          0.4  setosa\n",
      "6           4.6          3.4           1.4          0.3  setosa\n",
      "7           5.0          3.4           1.5          0.2  setosa\n",
      "8           4.4          2.9           1.4          0.2  setosa\n",
      "9           4.9          3.1           1.5          0.1  setosa\n",
      "(a).shape\n",
      "(150, 5)\n",
      "==================================================\n",
      "(b).all the columns\n",
      "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n",
      "==================================================\n",
      "(c).the 3rd element\n",
      "sepal_length       4.7\n",
      "sepal_width        3.2\n",
      "petal_length       1.3\n",
      "petal_width        0.2\n",
      "species         setosa\n",
      "Name: 2, dtype: object\n",
      "==================================================\n",
      "(d).the average of 'petal_width' where species is 'virginica'\n",
      "2.0260000000000002\n",
      "==================================================\n",
      "(e).the maximum of 'sepal_width' where species is 'setosa'\n",
      "4.4\n",
      "==================================================\n",
      "(f).the average value of sepal_length\n",
      "5.843333333333334\n",
      "==================================================\n",
      "(f).the maximum value of sepal_width\n",
      "4.4\n",
      "==================================================\n",
      "(f).the minimum value of petal_width\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "# The following piece of code creates a DataFrame \n",
    "# (a) Determine the shape of the dataframe\n",
    "# (b) Print out all the columns of the dataframe\n",
    "# (c) Print the 3rd element of the dataframe\n",
    "# (d) Find the average of 'petal_width' where species is 'virginica'\n",
    "# (e) Find the maximum of 'sepal_width' where species is 'setosa'\n",
    "# (f): What is the average value of sepal_length\n",
    "# (g): What is the maximum value of sepal_width\n",
    "# (h): What is the minimum value of petal_width\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "df.head(10) #prints the first 10 rows\n",
    "df_head10 = df.head(10)\n",
    "print(df_head10)\n",
    "\n",
    "# (a) Determine the shape of the dataframe\n",
    "print(\"(a).shape\")\n",
    "df_shape = df.shape\n",
    "print(df.shape)\n",
    "\n",
    "# (b) Print out all the columns of the dataframe\n",
    "print(\"=====\"*10)\n",
    "print(\"(b).all the columns\")\n",
    "df_col = df.columns\n",
    "print(df_col)\n",
    "\n",
    "# (c) Print the 3rd element of the dataframe\n",
    "print(\"=====\"*10)\n",
    "print(\"(c).the 3rd element\")\n",
    "df_3elem = df.iloc[2]\n",
    "print(df_3elem)\n",
    "\n",
    "# (d) Find the average of 'petal_width' where species is 'virginica'\n",
    "print(\"=====\"*10)\n",
    "print(\"(d).the average of 'petal_width' where species is 'virginica'\")\n",
    "mean_pw = df[df[\"species\"]=='virginica']['petal_width'].mean()\n",
    "print(mean_pw)\n",
    "\n",
    "# (e) Find the maximum of 'sepal_width' where species is 'setosa'\n",
    "print(\"=====\"*10)\n",
    "print(\"(e).the maximum of 'sepal_width' where species is 'setosa'\")\n",
    "max_sw = df[df[\"species\"]=='setosa']['sepal_width'].max()\n",
    "print(max_sw)\n",
    "\n",
    "# (f): What is the average value of sepal_length\n",
    "print(\"=====\"*10)\n",
    "print(\"(f).the average value of sepal_length\")\n",
    "avr_sl = df[\"sepal_length\"].mean()\n",
    "print(avr_sl)\n",
    "\n",
    "# (g): What is the maximum value of sepal_width\n",
    "print(\"=====\"*10)\n",
    "print(\"(f).the maximum value of sepal_width\")\n",
    "max_sew = df[\"sepal_width\"].max()\n",
    "print(max_sew)\n",
    "\n",
    "# (h): What is the minimum value of petal_width\n",
    "print(\"=====\"*10)\n",
    "print(\"(f).the minimum value of petal_width\")\n",
    "min_pw = df[\"petal_width\"].min()\n",
    "print(min_pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GRADED: Getting started on the capstone project\n",
    "We will start working on our capstone project this week. For this week, the task consists of\n",
    "Finding a dataset of interest.\n",
    "    -You can use the links in the supplementary materials to help you find the dataset\n",
    "    -This dataset should be publicly accessible and available for download\n",
    "    -Should be of interest to the class\n",
    "    -The goal is to be askign and answering important questions about the data\n",
    "You can start with the following datasets or find your own\n",
    "### Open datasets\n",
    "          \n",
    "* Resources for open data\n",
    "  * https://data.boston.gov/\n",
    "  * https://www.data.gov/\n",
    "  * https://www.bls.gov/data/\n",
    "  * http://www.fao.org/statistics/databases/en/\n",
    "  * http://ec.europa.eu/eurostat/web/main\n",
    "  * https://github.com/awesomedata/awesome-public-datasets\n",
    "  * https://www.kdnuggets.com/2016/05/top-10-datasets-github.html\n",
    "  * https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public\n",
    "    \n",
    "### Questions\n",
    "\n",
    "* Q: Shortlist three datasets of interest\n",
    "* Q: For each dataset suggest describe the data (a few sentences) and questions that can be answered using that data (a few sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1: Exchange Rates of US and UK\n",
    "\n",
    "    Data Description:\n",
    "    \n",
    "    The data period is from January 1976 to November 2015 with a sum of 479 observations. The data period is from January 1976 to November 2015 with a sum of 479 observations. Data is collected from several institutions. British pound per dollar nominal exchange rates are obtained from the Federal Reserve Bank of St. Louis Economic Data(FRED). This study uses the United Kingdom as the domestic country, so exchange rates are defined as domestic prices per unit of the dollar, therefore, a rise in exchange rate indicates a depreciation of the British pound. Short-term interest rates for both countries are money market rates.\n",
    "    \n",
    "    Question that can be answered:\n",
    "    Many literature suggests that exchanges rates are unable to predict since it follows a random walk. The random walk model is as follows: 𝑒t = 𝑒t+1 + 𝜈t. Therefore, I use this dataset to forecast the random walk model. By the definition of the random walk without drift, exchange rates follow a martingale difference process, in other words, E(et+1|et, et-1, …, e0) = et for all t; the best prediction of et+1 is et for all t >= 0. \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2: Interest Rates of US and UK, Exchange Rates of US and UK\n",
    "\n",
    "Data Description: \n",
    "\n",
    "Monthly variables. The data period is from January 1976 to November 2015 with a sum of 479 observations. Interest rates for the UK are downloaded from International Financial Statistics of the International Monetary Fund (IMF). Following Ince, Molodtsova and Papell (2015), for the U.S., interest rates before 2008 are federal fund rates(FFRs), and that after 2008 are replaced by Wu-Xia’s shadow FFRs.\n",
    "\n",
    "Questions that can be answered: \n",
    "\n",
    "Combine with dataset 1, test the uncovered interest rate parity (UIRP) which suggests that the interest rate differential is equal to the exchange rate differential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 3: Consumer Price Index (CPI) of UK and US\n",
    "\n",
    "Data Description:\n",
    "\n",
    "Monthly variables. The data period is from January 1976 to November 2015 with a sum of 479 observations. Consumer Price Index (CPI) is used to represent price levels.\n",
    "\n",
    "Question that can be answered:\n",
    "\n",
    "Using Purchasing Power Parity (PPP) fundamentals to forecast exchange rate. PPP suggests that the real prices of a basket of goods between two countries are the same, i.e. when converting domestic currency to foreign currency at the PPP rate, the same baskets of goods can be bought, which indicates the same price level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
