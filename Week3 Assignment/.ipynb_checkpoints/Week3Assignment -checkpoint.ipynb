{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "* Download the \"Assignment.ipynb\" notebook \n",
    "* Fill in the code in the cells marked with #GRADED#\n",
    "* Code cells outside of #GRADED# will not be considered for grading. \n",
    "  * Feel free to write outside of it for debugging\n",
    "* Submit the updated notebook\n",
    "  * Make sure to save your changes before submitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a)shape: (3, 5) Dimension: 2 Type: <class 'numpy.ndarray'>\n",
      "(b)sum: 105\n",
      "(c)mean: 7.0\n",
      "(d)\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "(e)\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "(f)\n",
      "[[  0   1   4   9  16]\n",
      " [ 25  36  49  64  81]\n",
      " [100 121 144 169 196]]\n",
      "(g)\n",
      "[[ 30  80 130]\n",
      " [ 80 255 430]\n",
      " [130 430 730]]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "# (a) Determine the shape, number of dimensions and type of \n",
    "# elements in the numpy array arr\n",
    "# (b) Determine the sum of elements in arr\n",
    "# (c) Determine the mean of elements in arr\n",
    "# (d) Create an array of the same shape as arr but filled with zeros\n",
    "# (e) Create an array of the same shape as arr but filled with ones\n",
    "# (f) Create an array of the same shape as arr but where all elements are squared values\n",
    "# (g) Create an array result of shape 3*3 resulting from multiplication of arr with transpose(arr). Hint: use np.dot\n",
    "arr = np.arange(15).reshape(3, 5)\n",
    "print('(a)shape:',arr.shape,'Dimension:', arr.ndim,'Type:',type(arr))\n",
    "print('(b)sum:',arr.sum())\n",
    "print('(c)mean:',arr.mean())\n",
    "print('(d)')\n",
    "print(np.zeros_like(arr))\n",
    "print('(e)')\n",
    "print(np.ones_like(arr))\n",
    "print('(f)')\n",
    "print(arr*arr)\n",
    "print('(g)')\n",
    "print(np.dot(arr,arr.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) (150, 5)\n",
      "(b)\n",
      "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n",
      "(c)\n",
      "sepal_length       4.7\n",
      "sepal_width        3.2\n",
      "petal_length       1.3\n",
      "petal_width        0.2\n",
      "species         setosa\n",
      "Name: 2, dtype: object\n",
      "(d) 2.0260000000000002\n",
      "(e) 3.8\n",
      "(f) 5.843\n",
      "(g) 4.4\n",
      "(h) 2.0\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "# The following piece of code creates a DataFrame \n",
    "# (a) Determine the shape of the dataframe\n",
    "# (b) Print out all the columns of the dataframe\n",
    "# (c) Print the 3rd element of the dataframe\n",
    "# (d) Find the average of 'petal_width' where species is 'virginica'\n",
    "# (e) Find the maximum of 'sepal_width' where species is 'setosa'\n",
    "# (f): What is the average value of sepal_length\n",
    "# (g): What is the maximum value of sepal_width\n",
    "# (h): What is the minimum value of petal_width\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "df.head(10) #prints the first 10 rows\n",
    "print('(a)',df.shape)\n",
    "print('(b)')\n",
    "print(df.columns)\n",
    "print('(c)')\n",
    "print(df.loc[2])\n",
    "d=df['species']== 'virginica'\n",
    "d=df.loc[d]\n",
    "print('(d)', np.mean(d.petal_width))\n",
    "e=df['species']== 'virginica'\n",
    "e=df.loc[e]\n",
    "print('(e)', e.sepal_width.max())\n",
    "print('(f)',round(df.sepal_length.mean(),3))\n",
    "print('(g)',df.sepal_width.max())\n",
    "print('(h)',df.sepal_width.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GRADED: Getting started on the capstone project\n",
    "We will start working on our capstone project this week. For this week, the task consists of\n",
    "Finding a dataset of interest.\n",
    "    -You can use the links in the supplementary materials to help you find the dataset\n",
    "    -This dataset should be publicly accessible and available for download\n",
    "    -Should be of interest to the class\n",
    "    -The goal is to be askign and answering important questions about the data\n",
    "You can start with the following datasets or find your own\n",
    "### Open datasets\n",
    "          \n",
    "* Resources for open data\n",
    "  * https://data.boston.gov/\n",
    "  * https://www.data.gov/\n",
    "  * https://www.bls.gov/data/\n",
    "  * http://www.fao.org/statistics/databases/en/\n",
    "  * http://ec.europa.eu/eurostat/web/main\n",
    "  * https://github.com/awesomedata/awesome-public-datasets\n",
    "  * https://www.kdnuggets.com/2016/05/top-10-datasets-github.html\n",
    "  * https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public\n",
    "    \n",
    "### Questions\n",
    "\n",
    "* Q: Shortlist three datasets of interest\n",
    "* Q: For each dataset suggest describe the data (a few sentences) and questions that can be answered using that data (a few sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* My first dataset that I am interested in is FBI's hate crime rate in 2014 from Data.GOV. This dataset mainly describes the number of 6 kinds of hate crime's happening: racism, religion, ethnicity, gender, disability and sexual orientation. It consists of 1826 rows of 15 variables; where each observation (row) corresponds to aparticular house in King County. In the U.S, there are two big different political slogans; \"For the People\" and \"Better Off Now\". Then, From these two different slogans, I have a question that the red states where support Republicans might have more the number of hate crimes than the blue states. Through the analysis, Massachusetts state has the most hate crimes, but California that supports democracy has the second most. In the result, the rate of hate crimes are more related with the population, not the ideology of policy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc = pd.read_csv(\"FBI-Hate-Crime.csv\")\n",
    "hc.columns\n",
    "hc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Race</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Disability</th>\n",
       "      <th>Sexual orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>California</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>California</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>73</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Race  Religion  Ethnicity Gender  Disability  \\\n",
       "14         Arizona    40        12         14      0           1   \n",
       "135     California    41        29          9      0           0   \n",
       "248     California    20         3         10      0           0   \n",
       "450       Illinois    22         2          3      0           0   \n",
       "486        Indiana    29         0          8      0           0   \n",
       "665  Massachusetts    73        21         15      0           0   \n",
       "892      Minnesota    20         4          3      0           1   \n",
       "904      Minnesota    24         4          0      0           0   \n",
       "921       Missouri    30         7          5      4           1   \n",
       "960         Nevada    27         9          6      0           0   \n",
       "\n",
       "     Sexual orientation  \n",
       "14                   14  \n",
       "135                  33  \n",
       "248                  17  \n",
       "450                  18  \n",
       "486                   6  \n",
       "665                  53  \n",
       "892                  11  \n",
       "904                   2  \n",
       "921                  14  \n",
       "960                  23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc2 = hc[['State', 'Race', 'Religion', 'Ethnicity', 'Gender','Disability','Sexual orientation']]\n",
    "hc2.Race.describe()\n",
    "hc2.State.describe()\n",
    "high_racism = hc2[hc2.Race >= 20]\n",
    "high_racism.head (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* My second dataset is about the House Sales in King County, USA dataset(www.kaggle.com). This dataset contains house sale prices for King County, it features homes sold between May 2014 and May 2015. It consists of 21613 rows of 21 variables; where each observation (row) corresponds to aparticular house in King County.As a lot of people each day are in the process of acquiring a home, it would be beneficial for them to get a better understanding of how house prices are formed. And I think I may answer the question \"Which factor mostly determine a house's price\". It is obviously a tough question to answer as many factors may play a rolein the final price at which a house is sold. Some of these factors depend on the house itsel such as its size,its condition, its location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house = pd.read_csv(\"house_data.csv\")\n",
    "house. columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house. shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The last dataset what I chosen is a survey on the smoking status of youths from 1999 to 2015(https://catalog.data.gov). This dataset provides data on both junior high school and high school students regarding exposure to environmental tobacco smoke, smoking cessation, school curriculum, minors' ability to purchase or otherwise obtain tobacco products, knowledge and attitudes about tobacco, and familiarity with pro-tobacco and anti-tobacco media messages. It consists of 10600 rows of 31 variables; cigarette smoking prevalence, cigarette smoking frequency, smokeless tobacco products prevalence and quit attempts. From this data set, I expect to be able to determine which factors encourage teenagers to smoke the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10600, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yts = pd.read_csv(\"Youth_Tobacco_Survey__YTS__Data.csv\")\n",
    "yts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'LocationAbbr', 'LocationDesc', 'TopicType', 'TopicDesc',\n",
       "       'MeasureDesc', 'DataSource', 'Response', 'Data_Value_Unit',\n",
       "       'Data_Value_Type', 'Data_Value', 'Data_Value_Footnote_Symbol',\n",
       "       'Data_Value_Footnote', 'Data_Value_Std_Err', 'Low_Confidence_Limit',\n",
       "       'High_Confidence_Limit', 'Sample_Size', 'Gender', 'Race', 'Age',\n",
       "       'Education', 'GeoLocation', 'TopicTypeId', 'TopicId', 'MeasureId',\n",
       "       'StratificationID1', 'StratificationID2', 'StratificationID3',\n",
       "       'StratificationID4', 'SubMeasureID', 'DisplayOrder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yts.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
